{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "mini_project_0728",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KU2I-L3wmVV",
        "outputId": "4493aa36-a71c-463f-fa1e-338225a566d4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME-Lf4YMKb3d"
      },
      "source": [
        "!cp /content/drive/MyDrive/MIB_lab/mydataset.py ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iMW8SeeFTDR"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from mydataset import myDataset\n",
        "\n",
        "#torch\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#torchvision\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.io import read_image\n",
        "\n",
        "#plot\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHYSOw9vcv7"
      },
      "source": [
        "#find path to train data and test data (images)\n",
        "data_dir = \"/content/drive/MyDrive/MIB_lab/images\"\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "# metadata array:\n",
        "csv_path1 = os.path.join(train_dir,'train.csv')\n",
        "csv_path2 = os.path.join(test_dir,'test.csv')\n",
        "## Metadata dataframe ##\n",
        "metadata1 = pd.read_csv( csv_path1, header=None )\n",
        "metadata2 = pd.read_csv( csv_path2, header=None )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldZv_HEpNIH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a38fe5db-6e2d-4372-b7b4-985ef01b47f0"
      },
      "source": [
        "# define transform used\n",
        "transform = transforms.Compose(\n",
        "    [#transforms.ToTensor(), \n",
        "     #output of torchvision dataset are PILImage range [0,1], ToTensor() convert this to Tensors\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "     transforms.Scale((150,150))\n",
        "     #transforms.ToTensor()\n",
        "     ])\n",
        "\n",
        "# retrieve the training and testing data from info obtained in csv files\n",
        "training_data = myDataset(metadata=metadata1,img_dir=train_dir,transform=transform)\n",
        "testing_data = myDataset(metadata=metadata2,img_dir=test_dir,transform=transform)\n",
        "\n",
        "# load the data with dataloader\n",
        "train_dataloader = DataLoader(training_data,batch_size=64,shuffle=True)\n",
        "test_dataloader = DataLoader(testing_data,batch_size=64,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:310: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgvlot7kFTDV"
      },
      "source": [
        "#import torch.nn and functional which contains all functions necessary to define a convolutional neural network\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# architecture construction\n",
        "class Net(nn.Module): \n",
        "    def __init__(self): \n",
        "        super().__init__()\n",
        "        # 4 convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=6,kernel_size=3,padding = 1) \n",
        "        self.conv2 = nn.Conv2d(in_channels=6,out_channels=12,kernel_size=3,padding = 1) \n",
        "        self.conv3 = nn.Conv2d(in_channels=12,out_channels=24,kernel_size=3,padding = 1) \n",
        "\n",
        "        # max pooling within 2x2\n",
        "        self.pool = nn.MaxPool2d(stride=2,kernel_size=2)\n",
        "\n",
        "        #3 linear layers\n",
        "        # 3,150,150->6,150,150->6,75,75->12,75,75->12,37,37\n",
        "        # ->24,37,37->24,18,18\n",
        "        self.fc1 = nn.Linear(24*18*18, 512)\n",
        "        self.fc2 = nn.Linear(512, 2)\n",
        "\n",
        "    def forward(self, x): #override forward function\n",
        "        # apply 1st conv layer, activate with relu\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        # apply 2nd, 3rd, and 4th conv layers, activate with relu\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "\n",
        "        # flatten all dimensions except batch to perform linear layers\n",
        "        x = torch.flatten(x, 1)\n",
        "        # apply linear layers, activate with relu\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "# initialize a net object\n",
        "net = Net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFEpXMOkFTDW"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # use Cross-entropy loss\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # use SGD with momentum for optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i45WMgfFTDX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f2d86d2-d870-46a8-f162-b33759bf747d"
      },
      "source": [
        "# training\n",
        "# train for 2 epochs\n",
        "for epoch in range(2): \n",
        "\n",
        "    # initiate running_loss\n",
        "    running_loss = 0.0 \n",
        "\n",
        "    for ith_batch,batch_data in enumerate(train_dataloader): \n",
        "        # obtain the images and labels\n",
        "        img_batch,labels_batch = batch_data['image'],batch_data['label']\n",
        "\n",
        "        # zero the parameter gradients (necessary because .backward() \n",
        "        # accumulate gradient for each parameter after each iteration)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        # feed the img_batch (input) into the network\n",
        "        outputs = net(img_batch)\n",
        "        # calculate the cross-entropy loss\n",
        "        loss = criterion(outputs, labels_batch)\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        # perform parameter update based on current gradient (stored in .grad) \n",
        "        # and update rule of SGD\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item() # .item() extracts loss values as floats\n",
        "        \n",
        "        # print every 10 mini-batches\n",
        "        if ith_batch % 10 == 9:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch+1, ith_batch+1, running_loss/10))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 0.688\n",
            "[1,    20] loss: 0.667\n",
            "[1,    30] loss: 0.652\n",
            "[1,    40] loss: 0.630\n",
            "[1,    50] loss: 0.604\n",
            "[1,    60] loss: 0.560\n",
            "[1,    70] loss: 0.502\n",
            "[2,    10] loss: 0.436\n",
            "[2,    20] loss: 0.385\n",
            "[2,    30] loss: 0.343\n",
            "[2,    40] loss: 0.287\n",
            "[2,    50] loss: 0.268\n",
            "[2,    60] loss: 0.259\n",
            "[2,    70] loss: 0.244\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udeUt4wtE_oa",
        "outputId": "0d5e6586-917e-4e42-991a-db5c1fc6f444"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader: # iterate through the data\n",
        "        images, labels = data['image'],data['label']\n",
        "        # calculate outputs by running images through the network \n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # increment total and correct\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "# print the accuracy\n",
        "print('Accuracy of the networks: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the networks: 90 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}