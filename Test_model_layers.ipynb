{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_model_layers",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElR1ofUz21DI",
        "outputId": "63afc802-b455-4dbf-99b3-451730dd7bf6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raHxfE2K3qcv"
      },
      "source": [
        "!cp /content/drive/MyDrive/MIB_lab/mydataset.py ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-jnkdDR24s1"
      },
      "source": [
        "## Install Required Packages ##\n",
        "# !pip istall --user torchvision\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from mydataset import myDataset\n",
        "\n",
        "## PyTorch ##\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "## TorchVision ##\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.io import read_image\n",
        "\n",
        "## Utils ##\n",
        "# from utils.ImageDataset import ImageDataset\n",
        "# from utils.EarlyStopping import EarlyStopping\n",
        "\n",
        "## Plot ##\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "## Seed ##\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "## CUDNN ##\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5K6iGSR29Hr"
      },
      "source": [
        "## FOR TESTING: Fraction of Training dataset to use ##\n",
        "train_fraction = 0.01\n",
        "\n",
        "## Images per batch ##\n",
        "batch_size= 7\n",
        "\n",
        "## Image Directory ##\n",
        "image_directory = '/content/drive/MyDrive/MIB_lab/images/train'\n",
        "\n",
        "# Metadata array:\n",
        "metadata_path= '/content/drive/MyDrive/MIB_lab/images/train/train.csv'\n",
        "\n",
        "## Metadata dataframe ##\n",
        "metadata = pd.read_csv( metadata_path, header=None )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWj81Ayt4CCu"
      },
      "source": [
        "class myDataset(Dataset):\n",
        "  def __init__(self,metadata,img_dir,transform=None):\n",
        "    #check if image_dir exist\n",
        "    if (not os.path.isdir(img_dir)):\n",
        "      exit('Directory does not exist.')\n",
        "    \n",
        "    self.img_labels = metadata\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_labels)\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    img_path = os.path.join(self.img_dir,str(self.img_labels.iloc[idx,0])+'.jpg')\n",
        "    _image = read_image(img_path)\n",
        "    label = self.img_labels.iloc[idx,1]\n",
        "\n",
        "    if _image.dtype == torch.uint8:\n",
        "      _image = _image/255.\n",
        "      \n",
        "    if self.transform:\n",
        "      _image = self.transform(_image)\n",
        "    \n",
        "    #return _image,label \n",
        "    return {'image':_image,'label':label}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MOBHK0g3B3J"
      },
      "source": [
        "## TESTING: Shuffle and Subset ##\n",
        "test_df= metadata.sample(frac=train_fraction).reset_index(drop=True)\n",
        "## Testing Dataset: Define ##\n",
        "test_dataset = myDataset(metadata=test_df, img_dir=image_directory, transform=None) \n",
        "\n",
        "## Testing Dataset: Dataloader ##\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=batch_size, \n",
        "    shuffle=False, \n",
        "    # num_workers=40\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQIYjoEJ3DwP"
      },
      "source": [
        "\n",
        "## Convolutional Encoder ## \n",
        "encoder = (\n",
        "            ## Conv, ReLu ##\n",
        "            nn.Conv2d(in_channels=3,out_channels=6,kernel_size=3,padding = 1), # Channels (3 -> 32) \n",
        "            nn.ReLU(),\n",
        "            ## MaxPool ##\n",
        "            nn.MaxPool2d( stride=2, kernel_size=2, padding=0), # Spatial (256 -> 128)\n",
        "            ## Conv, ReLu ##\n",
        "            nn.Conv2d(in_channels=6,out_channels=12,kernel_size=3,padding = 1), # Channels (64 -> 32)\n",
        "            nn.ReLU(),\n",
        "            ## MaxPool ##\n",
        "            nn.MaxPool2d( stride=2, kernel_size=2, padding=0),\n",
        "            ## Conv, ReLu ##\n",
        "            nn.Conv2d(in_channels=12,out_channels=24,kernel_size=3,padding = 1), # Channels (64 -> 32)\n",
        "            nn.ReLU(),\n",
        "            ## MaxPool ##\n",
        "            nn.MaxPool2d( stride=2, kernel_size=2, padding=0),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XlI7UbM3ITe",
        "outputId": "caee8560-ffb2-4264-efaf-7a3537db06c8"
      },
      "source": [
        "## First Image Batch ## \n",
        "first_batch= iter( test_loader ).next()['image']\n",
        "print('First Batch')\n",
        "print( '%s'% (first_batch.shape,) )\n",
        "print()\n",
        "\n",
        "print('### ENCODE ###')\n",
        "## Encoder: Iterate across Layer ##\n",
        "x = first_batch\n",
        "for layer in encoder:\n",
        "    print(layer)\n",
        "    x = layer(x)\n",
        "    if( type(layer) == torch.nn.modules.conv.Conv2d or\n",
        "       type(layer) == torch.nn.modules.MaxPool2d):\n",
        "        print( list( x.shape ) )\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Batch\n",
            "torch.Size([7, 3, 150, 150])\n",
            "\n",
            "### ENCODE ###\n",
            "Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "[7, 6, 150, 150]\n",
            "\n",
            "ReLU()\n",
            "\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "[7, 6, 75, 75]\n",
            "\n",
            "Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "[7, 12, 75, 75]\n",
            "\n",
            "ReLU()\n",
            "\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "[7, 12, 37, 37]\n",
            "\n",
            "Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "[7, 24, 37, 37]\n",
            "\n",
            "ReLU()\n",
            "\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "[7, 24, 18, 18]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}